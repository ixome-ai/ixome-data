import scrapy
from scrapy_selenium import SeleniumRequest
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC

class LutronSpider(scrapy.Spider):
    name = 'lutron'
    start_urls = ['https://www.lutron.com/en-US/Service-Support/Support']
    custom_settings = {
        'CLOSESPIDER_PAGECOUNT': 5  # Limit to 5 pages for testing
    }

    def start_requests(self):
        for url in self.start_urls:
            yield SeleniumRequest(
                url=url,
                callback=self.parse,
                wait_time=10,
                wait_until=EC.presence_of_element_located((By.TAG_NAME, 'p'))
            )

    def parse(self, response):
        # Extract text from paragraphs
        paragraphs = response.css('p::text').getall()
        for p in paragraphs:
            text = p.strip()
            if text:
                yield {'text': text}

        # Follow links to other support pages
        for next_page in response.css('a::attr(href)').getall():
            if 'support' in next_page.lower():
                yield SeleniumRequest(
                    url=response.urljoin(next_page),
                    callback=self.parse,
                    wait_time=10,
                    wait_until=EC.presence_of_element_located((By.TAG_NAME, 'p'))
                )
